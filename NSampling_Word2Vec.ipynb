{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwmGfEhTqMj5y9OTRZsi66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judem-21/Word2Vec-Model/blob/main/NSampling_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Word2Vec model (with Negative Sampling)"
      ],
      "metadata": {
        "id": "muzt6CP1Gqbw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF7XsLNXhz7V"
      },
      "source": [
        "####Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "me-hNcwXhajQ"
      },
      "outputs": [],
      "source": [
        "import torch,torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms as transforms\n",
        "#from torch.torchmetrics.text.bleu import BLEUScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QrDUgehUhzUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import spacy\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsuiniKF8YTK",
        "outputId": "1f4057a0-1426-4b07-9dec-a25133ab47dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.decomposition import PCA\n",
        "import torch\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Y89ZyiQnBkP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fed2beb-a7ff-4b1a-d429-348f6044cb3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNytP7BRN1QL"
      },
      "source": [
        "####Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAJmpQHviJOU",
        "outputId": "c6664fd7-a63e-4710-d9ce-78d74ce77082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2ScqFknWkYHX"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=3):\n",
        "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer(text):\n",
        "      return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        frequencies = {}\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "           lookup=self.tokenizer(sentence)\n",
        "           for word in lookup:\n",
        "            if word=='\\n' or word in stop_words or word in string.punctuation: continue\n",
        "\n",
        "            if word not in frequencies:\n",
        "              frequencies[word] = 1\n",
        "\n",
        "            else:\n",
        "              frequencies[word] += 1\n",
        "\n",
        "            if frequencies[word] == self.freq_threshold:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0dEBeB-3kjU_"
      },
      "outputs": [],
      "source": [
        "class seq2seq_dataset:\n",
        "    def __init__(self, data_file, num_samples=127584, freq_threshold=3):\n",
        "\n",
        "        self.data = pd.read_csv(data_file).values[:num_samples]\n",
        "\n",
        "\n",
        "        self.idx_sentences={}\n",
        "\n",
        "        for idx,lines in enumerate(self.data):\n",
        "            target_sentence = lines[0]\n",
        "            self.idx_sentences[idx]=target_sentence\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocabulary(self.idx_sentences.values())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_sentences_source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_i2-qurwANdn"
      },
      "outputs": [],
      "source": [
        "def get_dataset(\n",
        "    data_file,num_samples=8000,\n",
        "    freq_threshold=2):\n",
        "    dataset = seq2seq_dataset(data_file, num_samples=num_samples,freq_threshold=freq_threshold)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=get_dataset(data_file='/content/drive/MyDrive/Seq2SeqModel/output.csv',freq_threshold=4)"
      ],
      "metadata": {
        "id": "39VxrXMVYS4l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=dataset.idx_sentences.values()"
      ],
      "metadata": {
        "id": "7UyxNd9KYsZE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge_uyD-UW8o7",
        "outputId": "63ea7c83-cec7-4f74-e561-fc5085c731aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus='''Engineering is a profound and transformative discipline that fundamentally shapes human\n",
        "civilization through innovative problem-solving, technological advancement, and creative design\n",
        "across multiple domains. At its core, engineering represents a sophisticated synthesis of scientific\n",
        "principles, mathematical precision, and practical application, enabling humanity to overcome complex\n",
        "challenges and dramatically improve quality of life. From the towering skyscrapers that define modern\n",
        "urban landscapes to the intricate microprocessors powering global digital infrastructure, engineers are\n",
        "the architects of technological progress, continuously pushing boundaries of what is scientifically possible\n",
        "and economically viable. Mechanical engineering explores the intricate dynamics of motion, energy transfer,\n",
        "and mechanical systems, developing everything from microscopic medical devices to massive industrial\n",
        "machinery with remarkable computational precision. Electrical engineering revolutionizes communication,\n",
        "power generation, and electronic technologies, creating sophisticated networks that connect global\n",
        "populations and drive digital transformation. Civil engineering constructs the physical infrastructure\n",
        "supporting human societies - bridges, highways, water systems, and sustainable urban environments that\n",
        "enable complex social and economic interactions. Computer engineering merges software and hardware design,\n",
        "creating increasingly intelligent computational systems that reshape how humans interact with technology,\n",
        "from artificial intelligence algorithms to quantum computing platforms. Chemical engineering tackles\n",
        "critical global challenges by developing innovative materials, sustainable manufacturing processes, and\n",
        "advanced pharmaceutical solutions that address environmental and health-related complexities.\n",
        "Aerospace engineering enables humanity's exploration beyond terrestrial boundaries, designing spacecraft,\n",
        "satellites, and propulsion systems that expand our understanding of the universe. Biomedical engineering\n",
        "represents a cutting-edge intersection of medical science and technological innovation, developing\n",
        "prosthetics, diagnostic tools, and regenerative medical technologies that dramatically improve human\n",
        "health outcomes. Environmental engineering addresses urgent global sustainability challenges, designing\n",
        "solutions for renewable energy, waste management, and ecological conservation. Each engineering discipline\n",
        "contributes uniquely to human progress, representing a dynamic, intellectually rigorous profession that\n",
        "demands continuous learning, creativity, and a profound commitment to solving increasingly complex global\n",
        "challenges through systematic, innovative approaches. Engineering represents an extraordinary intellectual and\n",
        "technological frontier that transcends traditional disciplinary boundaries, embodying humanity's most ambitious aspirations\n",
        "for scientific innovation, societal transformation, and global problem-solving through sophisticated computational methodologies,\n",
        "advanced design principles, and interdisciplinary collaboration. This monumentally complex profession encompasses an intricate, dynamically\n",
        "evolving network of specialized domains, each contributing uniquely to human progress through rigorous scientific investigation, cutting-edge\n",
        "technological development, and systematic approaches to addressing increasingly complex global challenges across multiple dimensions of human\n",
        "experience. Mechanical engineering emerges as a foundational discipline that meticulously explores the intricate interactions between complex\n",
        "physical systems, materials science, energy transfer mechanisms, and dynamic computational modeling, developing revolutionary technologies\n",
        "ranging from microscopic medical nanomachines to massive industrial infrastructure, aerospace propulsion systems, and advanced robotic platforms\n",
        "that dramatically expand human technological capabilities and scientific understanding. Electrical engineering fundamentally revolutionizes global\n",
        "communication, computational infrastructure, and technological ecosystems by creating sophisticated networks, semiconductor technologies, quantum\n",
        "computing architectures, and advanced electronic systems that interconnect billions of individuals, transform information exchange paradigms,\n",
        "and enable unprecedented levels of computational intelligence and technological integration across diverse global contexts. Computer engineering\n",
        "represents the quintessential frontier of technological innovation, seamlessly merging hardware and software design principles to create increasingly\n",
        "           intelligent computational platforms, artificial intelligence algorithms, machine learning ecosystems, and transformative digital technologies that reshape human\n",
        "           interaction, decision-making processes, and technological engagement through increasingly complex and adaptive computational frameworks. Civil engineering\n",
        "           constructs the fundamental physical infrastructure supporting human civilization, designing resilient, sustainable, and technologically advanced urban environments,\n",
        "           transportation networks, water management systems, and architectural solutions that address complex social, economic, and environmental challenges while simultaneously\n",
        "           promoting human connectivity, resource efficiency, and ecological sustainability. Chemical engineering tackles critical global challenges by developing innovative\n",
        "           materials, sustainable manufacturing processes, advanced pharmaceutical solutions, and transformative biotechnological platforms that address environmental degradation,\n",
        "           energy efficiency, human health complexities, and the intricate interactions between technological systems and natural ecosystems. Aerospace engineering enables humanity's\n",
        "           most audacious technological dreams, designing sophisticated spacecraft, satellite systems, propulsion technologies, and exploration platforms that expand human understanding\n",
        "           of the universe, push the boundaries of scientific exploration, and create revolutionary technologies for interplanetary research and technological innovation. Biomedical\n",
        "           engineering emerges as a groundbreaking interdisciplinary domain, combining medical science, computational technologies, and advanced engineering principles to develop\n",
        "           regenerative medical solutions, personalized healthcare platforms, advanced diagnostic technologies, prosthetic systems, and transformative medical interventions that\n",
        "           dramatically improve human health outcomes, extend medical capabilities, and create unprecedented opportunities for technological intervention in human physiological systems.\n",
        "           Environmental engineering addresses urgent global sustainability challenges by creating innovative solutions for renewable energy generation, ecological conservation, climate\n",
        "           change mitigation, waste management, and sustainable technological development that are increasingly critical to human survival, planetary health, and long-term ecological\n",
        "           equilibrium. Each engineering discipline contributes a unique, sophisticated perspective to the grand narrative of human technological progress, representing a dynamic,\n",
        "           intellectually rigorous profession that demands continuous learning, extraordinary creativity, interdisciplinary collaboration, and an unwavering commitment to solving\n",
        "           increasingly complex global challenges through systematic, innovative, and transformative approaches that push the boundaries of human knowledge and technological capability.'''\n",
        "\n",
        "'''sentences=corpus.split('.')\n",
        "tokenised_words=word_tokenize(corpus)\n",
        "stop_words = set(stopwords.words('english'))'''"
      ],
      "metadata": {
        "id": "7hxW7rOGB3Dw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90034eca-80a0-43cf-a34b-f65a5013b955"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"sentences=corpus.split('.')\\ntokenised_words=word_tokenize(corpus)\\nstop_words = set(stopwords.words('english'))\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Data PreProcess"
      ],
      "metadata": {
        "id": "n1rwAh2zYCVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extraction(sentences,string2idx,window_size=2):\n",
        "  data=[]\n",
        "  for sentence in sentences:\n",
        "    words=[tok.text.lower() for tok in spacy_eng.tokenizer(sentence)]\n",
        "    for i in range(len(words)):\n",
        "      token=words[i].lower()\n",
        "      if token in string.punctuation or token in stop_words or token not in string2idx: continue\n",
        "      for j in range(max(0,i-window_size),min(len(words),i+window_size+1)):\n",
        "        if i!=j:\n",
        "          if words[j].lower() not in stop_words and words[j] not in string.punctuation and words[j].lower() in string2idx:data.append([string2idx[words[i].lower()],string2idx[words[j].lower()]])\n",
        "  return data"
      ],
      "metadata": {
        "id": "vvpMsOD7FsTd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string2idx=dataset.vocab.stoi\n",
        "data=data_extraction(sentences,string2idx,window_size=5)\n",
        "data=torch.tensor(data)"
      ],
      "metadata": {
        "id": "Lu9KMDzMNSAD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLDwPsOsFpsH",
        "outputId": "631a7a61-c009-48aa-e180-498d52a01e17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([151406, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model"
      ],
      "metadata": {
        "id": "LjgHjqrYYFJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram_model(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim):\n",
        "    super(SkipGram_model,self).__init__()\n",
        "    self.embeddings_centre=nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.embeddings_context=nn.Embedding(vocab_size,embedding_dim)\n",
        "\n",
        "  def forward(self,centre,context):\n",
        "    centre_embed=self.embeddings_centre(centre)\n",
        "    context_embed=self.embeddings_context(context)\n",
        "    scores=torch.cosine_similarity(centre_embed,context_embed,dim=1)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "wTChU5w1Ffnz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model=SkipGram_model(vocab_size=len(string2idx),embedding_dim=32).to(device)\n",
        "loss=nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "Qwh7b_QB7SdG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training"
      ],
      "metadata": {
        "id": "nRxIYW9S2tvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,centre,context,vocab_size,loss_function,optimizer,batch_size,num_epochs=1000,lr=0.01,negative_sampling_ratio=5,device='cuda'):\n",
        "  num_batches=centre.shape[0]//batch_size\n",
        "  epoch_loss=[]\n",
        "  for epoch in range(num_epochs):\n",
        "    batch_loss=[]\n",
        "    for batch in range(num_batches):\n",
        "      batch_centre=centre[batch*batch_size:(batch+1)*batch_size].to(device)\n",
        "      batch_context=context[batch*batch_size:(batch+1)*batch_size].to(device)\n",
        "\n",
        "      #positive_samples\n",
        "      pos_label=torch.ones(batch_size).to(device)\n",
        "      pos_out=model(batch_centre,batch_context)\n",
        "      pos_loss=loss_function(pos_out,pos_label)\n",
        "\n",
        "      #negative_samples\n",
        "      counter=0\n",
        "      neg_loss=0\n",
        "      while counter<negative_sampling_ratio:\n",
        "        neg_context=torch.randint(low=0,high=vocab_size,size=(batch_size,)).to(device)\n",
        "        if (batch_context==neg_context).all() or (batch_centre==neg_context).any(): continue\n",
        "        neg_label=torch.zeros(batch_size).to(device)\n",
        "        neg_out=model(batch_centre,neg_context)\n",
        "        neg_loss+=loss_function(neg_out,neg_label)\n",
        "        counter+=1\n",
        "      total_loss=pos_loss+(neg_loss/negative_sampling_ratio)\n",
        "      batch_loss.append(total_loss.item())\n",
        "      if (epoch==0 and batch==0) or (((epoch+1)%(num_epochs//5))==0 and ((batch+1)%1000)==0):\n",
        "        print(f'Epoch {epoch+1}-Batch {batch+1}:- Loss={total_loss.item()}')\n",
        "      optimizer.zero_grad()\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "    total_loss=np.mean(batch_loss)\n",
        "    epoch_loss.append(total_loss)\n",
        "  return model,epoch_loss"
      ],
      "metadata": {
        "id": "rfIZVWOdytCX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10000;lr=0.001\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "batch_size=64\n",
        "total_samples=batch_size*(len(data)//batch_size)\n",
        "centre=data[:total_samples,0]\n",
        "context=data[:total_samples,1].to(device)\n",
        "model,epoch_loss=train(model,centre,context,len(string2idx),loss,optimizer,batch_size,num_epochs=epochs,lr=lr,negative_sampling_ratio=5,device=device)"
      ],
      "metadata": {
        "id": "w6YoPQ3oGFRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d167849e-4f2a-419c-9353-75b0b50af0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1-Batch 1:- Loss=1.4023714065551758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Testing"
      ],
      "metadata": {
        "id": "lz5imQ-cYIIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings=model.embeddings.weight.detach().cpu().numpy()\n",
        "embedding_choices=np.random.choice(np.arange(len(string2idx)),size=100,replace=False)\n",
        "print(f'Word embeddings shape: {word_embeddings[embedding_choices].shape}')\n",
        "pca=PCA(n_components=3).fit_transform(word_embeddings[embedding_choices])\n",
        "print(f'pca shape: {pca.shape}')\n",
        "fig=plt.figure(figsize=(20,20))\n",
        "ax=fig.add_subplot(111,projection='3d')\n",
        "for idx,word_idx in enumerate(embedding_choices):\n",
        "    #print(word,idx)\n",
        "    x,y,z=pca[idx]\n",
        "    ax.scatter(x,y,z,color='blue')\n",
        "    ax.text(x,y,z,dataset.vocab.itos[word_idx])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iHveHgYjlK-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}